---
title: "SmartAllocate – Predicting EMS Response for Smarter, More Efficient Ambulance Allocation"
author: "Sara Mattio and Kate Sutton"
date: "12/20/2019"
output: 
  html_document:
    theme: united
    toc: true
    toc_float: true
    number_sections: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include= FALSE}
library(viridis)
library(marmap)
library(ggplot2)
library(tidyverse)
library(sf)
library(lubridate)
library(tigris)
library(tidycensus)
library(gganimate)
library(viridis)
library(riem)
library(gridExtra)
library(knitr)
library(kableExtra)
library(stargazer)

census_api_key("bb77f2a147934164e965121bd02b5cc9e22f3165")

```

```{r include=FALSE}
mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}

plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "grey80", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}

palette5 <- c("#eff3ff","#bdd7e7","#6baed6","#3182bd","#08519c")
palette4 <- c("#D2FBD4","#92BCAB","#527D82","#123F5A")
palette3 <- c("#6baed6","#3182bd","#08519c")
palette2 <- c("#6baed6","#08519c")

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                          c(.01,.2,.4,.6,.8), na.rm=T)
  }
}

q5 <- function(variable) {as.factor(ntile(variable, 5))}
```

```{r include = FALSE}
calls <- read.csv("C:/Users/ssmat/Desktop/MUSA507/Final_Project/EMScalls_cleaned.csv", stringsAsFactors = FALSE) %>%
  st_as_sf(coords = c("geo1", "geo2"), crs = 102747, agr = "constant")

VB_CT <- st_read("https://opendata.arcgis.com/datasets/82ada480c5344220b2788154955ce5f0_2.geojson") %>%
  st_transform(102747)

VB_CT <- subset(VB_CT, SHAPEarea < 500000000)

calls_in_tracts <- st_join(calls, VB_CT)
calls <- subset(calls_in_tracts, OBJECTID>0)
```



Over the past 30 years, communication technologies have changed dramatically. As these technologies evolved, emergency response technology has lagged in modernization. The National Emergency Number Association (NENA) identified a need to completely overhaul the nation’s 911 systems in 2000; however, most municipalities have been slow to adapt this project. Unfortunately, out-of-date technology can result in slower emergency response – an inefficiency with potentially fatal outcomes.


Changes in business practices and adoption of new technology can be a challenging, lengthy process for small municipalities. While counties gradually improve emergency dispatch technology, it is possible to integrate intelligent, predictive algorithms into current business practices to optimize emergency response. This report analyzes the predictive modeling of SmartAllocate, an algorithm that increases efficiency in EMS response time by predicting the volume of EMS calls at any given time and day. By understanding where and when peak demand exists, ambulances are effectively allocated to the appropriate stations to handle predicted demand. 


Incorporating intelligent predictive algorithms into emergency response has the potential to reduce fatal outcomes and reduce municipal spending. In this report, the process of building a predictive model for this use case will be analyzed with data provided by the City of Virginia Beach’s Open Data Portal. 


**Click [here](https://youtu.be/Ir93h7-oi2Q) for the video presentation of this project.**


# The Data

The City of Virginia Beach has released an EMS Calls for Service dataset on their Open Data Portal which contains the date, time, location, and nature of the medical emergency for selected calls between 2010 and 2018. During the time this analysis took place, the City of Virginia Beach's Open Data Portal underwent changes that resulted in the removal of the geocoded dataset used in this analysis. As a result, the only data made available to us was from June 14, 2010 to June 22, 2010. In total, the sample set contains 941 calls. Therefore, any tests and cross-validation conducted on the model could only utilize a small amount of data. Despite the limitations, this sample still serves as a useful cross-section of data as it takes place during Virginia Beach's high season in the summer.



## Reporting Bias in Emergency Calls
It should be noted that reporting bias likely exists in this dataset. With the exception of severe medical emergencies, it is likely that certain groups are more or less likely to call 911 for medical emergencies. Studies have found that those who have good health, good health insurance, no medical history, and no burden of medical costs are more likely to call 911 to report a medical emergency. Groups less likely to call 911 include those over the age of 65, of lower socioeconomic status, male, and in fair or poor health (Seo, M., Begley, C., Langabeer, J. R., & DelliFraine, J. L., 2014). According to 2017 ACS 5-Year Estimates, nearly 13% of Virginia Beach is over the age of 65 and 18.4% of the population earns less than $25,000 per year. An estimated 8.9% of the population does not have health insurance coverage. While this model may have utility in predicting emergency medical *calls*, these results are likely to be inconsistent to where medical emergencies are actually taking place due to underreporting. 


# Exploring The Data

```{r include = FALSE}
VB_Census <-
  get_acs(geography = "tract",
          variables = c("B01003_001", "B19013_001",
                        "B02001_002", "B08013_001",
                        "B08012_001", "B08301_001",
                        "B08301_010", "B01002_001"),
          year = 2010,
          state = "VA",
          geometry = TRUE,
          county=c("Virginia Beach"),
          output = "wide") %>%
  rename(Total_Pop =  B01003_001E,
         Med_Inc = B19013_001E,
         Med_Age = B01002_001E,
         White_Pop = B02001_002E,
  ) %>%
  mutate(Percent_White = White_Pop / Total_Pop)
```


First, calls were mapped out to understand which areas are receiving the most calls. As expected, many calls are located along arterial roads in northern Virginia Beach, indicating that traffic accidents may serve as a useful predictive indicator.  


![EMS Call Volume in Virginia Beach](C:/Users/ssmat/Desktop/MUSA507/Final_Project/HeatMapBetter.png) 


This map shows the number of ambulances at each station, indicating that ambulances seem to be already well dispersed based on existing demand. 

![Dispatch Stations in Virginia Beach, Symbolized by Ambulance Count](C:/Users/ssmat/Desktop/MUSA507/Final_Project/EMSCallsMap.png) 


A relationship may also exist between the number of calls and certain demographic indicators, such as age, income, and race. The map below shoes the median age for census tracts using 2010 Census data from `tidycensus`. As previously suggested, tracts that have higher median ages seem to make less calls, while lower median age census tracts have a higher call density. 


```{r fig.cap = "...", echo = FALSE}
VB_Census %>%
    ggplot(aes(fill= Med_Age))+
    labs(title = "Median Age in Virginia Beach",
         subtitle = "2010")+
    geom_sf(color = NA)+
    scale_fill_viridis_c(option = "magma")
```


Mapping median household income results in a slightly different outcome than expected. Lower EMS call volume seems to occur in census tracts wtih a highest median income, but tracts with an average household income of $60,000 to $90,000 seem to be located in high-volume areas. 



```{r echo = FALSE}
VB_Census %>%
    ggplot(aes(fill= Med_Inc))+
    labs(title = "Median Income in Virginia Beach",
         subtitle = "2010")+
    geom_sf(color = NA)+
    scale_fill_viridis_c(option = "magma")
```


Race data shows a possible relationship between mainly white census tracts and medical emergency calls.

```{r echo = FALSE}
VB_Census %>%
    ggplot(aes(fill= Percent_White))+
    labs(title = "Percent White Population in Virginia Beach",
         subtitle = "2010")+
    geom_sf(color = NA)+
    scale_fill_viridis_c(option = "magma")
```


Finally, given the relationship between weather and traffic accidents, weather conditions may also be a useful predictor for EMS call volume. Using the `riem` package, a weather panel can be created for the date range of the sample. 

```{r echo = FALSE}
weather.Panel <- 
  riem_measures(station = "NTU", date_start = "2010-06-14", date_end = "2010-06-22") %>%
  replace(is.na(.), 0) %>%
    mutate(interval60 = ymd_h(substr(valid,1,13))) %>%
    mutate(week = week(interval60),
           dotw = wday(interval60, label=TRUE)) %>%
    group_by(interval60) %>%
    summarize(Temperature = max(tmpf),
              Precipitation = sum(p01i),
              Wind_Speed = max(sknt)) %>%
    mutate(Temperature = ifelse(Temperature == 0, 42, Temperature))

summary(weather.Panel)
```

The data is then categorized by precipitation, wind speed, and temperature for the time period of this analysis. Weather patterns during this time, particularly high heat and precipitation may cause more health emergencies and traffic accidents, resulting in increased medical emergency calls. 

``` {r echo = FALSE}
grid.arrange(
  ggplot(weather.Panel, aes(interval60,Precipitation)) + geom_line() + 
    labs(title="Percipitation", x="Hour", y="Perecipitation") + plotTheme(),
  ggplot(weather.Panel, aes(interval60,Wind_Speed)) + geom_line() + 
    labs(title="Wind Speed", x="Hour", y="Wind Speed") + plotTheme(),
  ggplot(weather.Panel, aes(interval60,Temperature)) + geom_line() + 
    labs(title="Temperature", x="Hour", y="Temperature") + plotTheme(),
  top="Weather Data - Virginia Beach - June 14-22, 2010")
```



# The Model

It should be noted that because a limited sample set of data was provided to us by the City of Virginia Beach's Open Data Portal, we were unable to train and test the model on a large sample size nor on a wider time period. 


## Space-Time Process

Because the data has both spatial and temporal features, the space-time process creates time-based features that are combined with spatial features to create a panel with every possible observation for space-time combinations. The `EMS_calls` dataset contains several temporal features, including dispatch time and entry date, but for this analysis, the `call_date_and_time` field was chosen. A 60-minute time interval was added to eventually create time lags. The resulting `Call_Time` panel is shown below.

```{r message = FALSE, warning= FALSE}
study.panel <- 
  expand.grid(interval60 = unique(calls$interval60),
              TRACTCE10 = unique(calls$TRACTCE10))

call.panel <- 
  calls %>%
  mutate(Call_Counter = 1) %>% 
  right_join(study.panel) %>% 
  group_by(interval60, TRACTCE10) %>%
  summarize(Call_Count = sum(Call_Counter, na.rm=T))

call.panel$interval60.3 <- parse_date_time(call.panel$interval60, orders = "mdy hm")

call.panel$week <- week(call.panel$interval60.3)
call.panel$dotw <- wday(call.panel$interval60.3)
```

To incorporate the weather data to the panel, the time field is cleaned up with the `is.POSIXct` function and joined to the `call.panel`.
```{r include=FALSE}
is.POSIXct(weather.Panel$interval60.3)
is.POSIXct(call.panel$interval60.3)
```

``` {r message = FALSE, warning= FALSE}
weather.Panel$interval60.3 <- parse_date_time(weather.Panel$interval60, orders = "ymd hms")

call.panel <- left_join(call.panel, weather.Panel, by = c("interval60.3", "interval60.3"))
```
\s\s

Next, to predict time series trends, time lags are incorporated into the model. Time lags provide additional insight into call volume during a given time period through the comparison of the hours before and after high-volume time periods. Because this sample set contains a holiday that may affect EMS call volume (Father's Day), holiday features were incorporated into the model as fixed effects.

```{r warning = FALSE, message=FALSE}
call.panel <- 
  call.panel %>% 
  arrange(TRACTCE10, interval60.3) %>% 
  mutate(lagHour = dplyr::lag(Call_Count,1),
         lag2Hours = dplyr::lag(Call_Count,2),
         lag3Hours = dplyr::lag(Call_Count,3),
         lag4Hours = dplyr::lag(Call_Count,4),
         lag12Hours = dplyr::lag(Call_Count,12),
         lag1day = dplyr::lag(Call_Count,24),
         holiday = as.factor(ifelse(yday(interval60.3) == 171,1,0))) %>%
  mutate(day = yday(interval60.3)) %>%
  mutate(holidayLag = case_when(
                                dplyr::lead(holiday, 1) == 1 ~ "MinusOneDay"),
         holidayLag = replace_na(holidayLag, 0))

dplyr::select(st_set_geometry(call.panel, NULL), 
              interval60.3, TRACTCE10, Call_Count, 
              lagHour, lag2Hours)
```



By breaking down the number of calls by day, several patterns occur. During the weekday, fewer calls take place in the early morning, while volume seems to increase mid-day. On the weekends, volume appears to be lower and steadier. For the last day of the set, only a limited amount of calls were provided in the dataset, resulting in a perceived abnormal volume. 

```{r echo=FALSE, message = FALSE, warning = FALSE, fig.width=16, fig.height=8}
as.data.frame(call.panel) %>%
  group_by(day, interval60.3) %>% 
  summarize(Call_Count = sum(Call_Count)) %>%
    ggplot(aes(interval60.3,Call_Count)) + 
      geom_line() +
      plotTheme() +
      facet_wrap(~day, scales="free", ncol=3) +
      ylim(0,20) +
      labs(title="EMS calls in Virginia Beach by day: June 14 through 22, 2010",
           x="Day", y="Trip Counts") 
```


The plots below explore the relationship between EMS call counts and time lag functions. Based on the close correlation of these features in all time lag functions, these functions should serve as a strong predictor. 


```{r echo=FALSE, message = FALSE, warning = FALSE, fig.width=12, fig.height=8}
plotData.lag <-
  as.data.frame(call.panel) %>%
  group_by(interval60.3) %>% 
  summarise_at(vars(starts_with("lag"), "Call_Count"), mean, na.rm = TRUE) %>%
  gather(Variable, Value, -interval60.3, -Call_Count) %>%
  mutate(Variable = factor(Variable, levels=c("lagHour","lag2Hours","lag3Hours","lag4Hours",
                                              "lag12Hours")))

correlation.lag <-
  plotData.lag %>%
  group_by(Variable) %>%  
  summarize(correlation = round(cor(Value, Call_Count),2))

plotData.lag %>%
  ggplot(aes(Value, Call_Count)) + 
  geom_point() + geom_smooth(method = "lm", se = F) + 
  facet_wrap(~Variable) +
  geom_text(data=correlation.lag, aes(label=paste("R =", correlation)),colour = "blue", 
            x=-Inf, y=Inf, hjust=-0.1, vjust=1.2) +
  labs(title = "EMS call count as a function of time lags", 
       subtitle= "One week in June, 2010", x = "Lag Call Count") +
  plotTheme()
```


## The Final Model

To train and test the model, `call.Train` and `call.Test` datasets were formed. Four regression models were developed using an increasing amount of indicators. The final two include time lag features. 

```{r message = FALSE, warning = FALSE}
call.panel$tract2 <- as.character(call.panel$TRACTCE10)
call.Train <- subset(call.panel, week == 24 & dotw < 7)
call.Test <- filter(call.panel, day > 169)

reg1 <- 
  lm(Call_Count ~  hour(interval60.3) + dotw ,  data=call.Train)

reg2 <-
  lm(Call_Count ~ hour(interval60.3) + dotw + tract2, data = call.Train)

reg3 <-
  lm(Call_Count ~ hour(interval60.3) + dotw + tract2 + lagHour +lag2Hours + 
       lag3Hours + lag4Hours + lag12Hours, data = call.Train)

reg4 <- lm(Call_Count ~ hour(interval60.3) + dotw + tract2 + lagHour +lag2Hours + 
             lag3Hours + lag4Hours + lag12Hours + Temperature + Precipitation + Wind_Speed, data = call.Train)
```

\s\s

## Testing and Validating the Model

To test the model, a nested data frame of the test data by week. A functin is created (`model_pred`) that can be mapped onto each data frame of the nested structure. 

```{r message = FALSE, warning = FALSE}
call.Test.weekNest <- 
  call.Test %>%
  filter(!is.na(lagHour))%>%
  filter(!is.na(lag2Hours))%>%
  filter(!is.na(lag3Hours))%>%
  filter(!is.na(lag4Hours))%>%
  filter(!is.na(lag12Hours))%>%
  nest(-week)

model_pred <- function(dat, fit){
  pred <- predict(fit, newdata = dat)
  }
```

\s\s

The predictions can then be run and summarized as follows. The results show that 0.0531 calls take place per hour per census tract in Virginia Beach. This number seems lower than expected, which can be explained by the limited number of records in the dataset.  

```{r message = FALSE, warning = FALSE}
week_predictions <- 
  call.Test.weekNest %>% 
  mutate(ATime = map(.x = data, fit = reg1, .f = model_pred),
         BTime_Space = map(.x = data, fit = reg2, .f = model_pred),
         CTime_Space_TimeLag = map(.x = data, fit = reg3, .f = model_pred),
         DTime_Space_TimeLag_Weather = map(.x = data, fit = reg4, .f = model_pred))

week_predictions <-
  week_predictions %>% 
  gather(Regression, Prediction, -data, -week) %>%
  mutate(Observed = map(data, pull, Call_Count),
         Absolute_Error = map2(Observed, Prediction,  ~ abs(.x - .y)),
         MAE = map_dbl(Absolute_Error, mean, na.rm = TRUE),
         sd_AE = map_dbl(Absolute_Error, sd, na.rm = TRUE))

week_predictions

call.Test.weekNest %>%
  mutate(Call_Count = map(data, pull, Call_Count),
         Mean_Call_Count = map_dbl(Call_Count, mean))
```

\s\s
To analyze the model further, the Mean Absolute Errors (MAE) for each model can be shown by week. It appears that the differences among the four models are minimal, although incorporating weather features improved the model slightly. Time lag features appears to have worsened the model slightly; however the difference is minimal. 

```{r echo=FALSE, message = FALSE, warning = FALSE}
week_predictions %>%
  dplyr::select(week, Regression, MAE) %>%
  gather(Variable, MAE, -Regression, -week) %>%
  ggplot(aes(week, MAE)) + 
  geom_bar(aes(fill = Regression), position = "dodge", stat="identity") +
  scale_fill_manual(values = palette5) +
  labs(title = "Mean Absolute Errors by model specification and week") +
  plotTheme()

```



Finally, the mean and predicteed observed volume of calls can be observed to compare goodness of fit. While Model D appears to be somewhat closely aligned, the other models do not match the predicted observations as closely as expected. The correlation plots for calls and time lag do not seems to be as strong of a predictor as originally suggested. 


```{r echo=FALSE, message = FALSE, warning = FALSE}
week_predictions %>% 
  mutate(interval60.3 = map(data, pull, interval60.3),
         TRACTCE10 = map(data, pull, TRACTCE10)) %>%
  dplyr::select(interval60.3, TRACTCE10, Observed, Prediction, Regression) %>%
  unnest() %>%
  gather(Variable, Value, -Regression, -interval60.3, -TRACTCE10) %>%
  group_by(Regression, Variable, interval60.3) %>%
  summarize(Value = mean(Value)) %>%
  ggplot(aes(interval60.3, Value, colour=Variable)) + 
  geom_line(size = 1.1) + 
  facet_wrap(~Regression, ncol=1) +
  scale_colour_manual(values = palette2) +
  labs(title = "Mean Predicted/Observed EMS call volume by hourly interval", 
       subtitle = "Virginia Beach; A test set of 2 weeks in June", x = "Hour", y= "EMS Calls") +
  plotTheme()
```


This analysis intended to include validation tests by space; however, the model produced too many `NA` values and results could not be mapped. 

# Conclusion
The idea behind this analysis was to explore data related to EMS call volume and utilize these features in a model which would ultimately be tested to determine accuracy and generalizability. While Model D was somewhat accurate in its predictions with an average MAE of 0.0984, compared to the average MAE of the tracts of 0.0531, the model's MAE is not as strong. It is very surprising that models with time lag features did not show an improvement over those without time lag features, especially considering the correlation values for time lag features were above 0.90. Identifying the source of this problem would create the most substantial improvement in this model. 

As far as the generalizability of the model, the model is not accurate enough to assess its generalizability. Despite the initial shortcomings of the model at this stage, there is strong potential for improvement in further stages of development. First, a significantly larger sample size should be used. Without the API from the City's Open Data Portal, it was challenging to properly assess a wide selection of data. Although geocoded data was provided to us by another group, the datetime formatting created a lot of issues and we chose to use the data we already had saved in our environment instead. Having at least 10,000 records would have allowed for a more thorough analysis. The time period used was also problematic. Unfortunately, the only data available to us was from a 9-day time period in June 2010. Creating a time-space model with 9 days worth of data was challenging and ultimately not useful in creating a generalizable model. In future stages of development of this model, using a larger, more recent dataset could create a more robust model. 
